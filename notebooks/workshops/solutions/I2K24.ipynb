{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I2k Workshop 2024 - Exploiting NanoPyxâ€™s Liquid Engine to accelerate image analysis pipelines \n",
    "\n",
    "## NanoPyx\n",
    "\n",
    "<img src=\"https://github.com/HenriquesLab/NanoPyx/raw/main/.github/logo.png\" align=\"right\" width=\"300\"/>\n",
    "\n",
    "### What is the NanoPyx ðŸ”¬ Library?\n",
    "\n",
    "NanoPyx is a library specialized in the analysis of light microscopy and super-resolution data.\n",
    "It is a successor to [NanoJ](https://github.com/HenriquesLab/NanoJ-Core), which is a Java library for the analysis of super-resolution microscopy data.\n",
    "\n",
    "NanoPyx focuses on performance, by using the [Liquid Engine](https://github.com/HenriquesLab/LiquidEngine) at its core.\n",
    "\n",
    "The source code documentation for nanopyx can be found [here](https://henriqueslab.github.io/NanoPyx/nanopyx.html).\n",
    "\n",
    "## Liquid Engine\n",
    "\n",
    "The Liquid Engine is a high-performance, adaptive framework designed to optimize computational workflows for bioimage analysis. It dynamically generates optimized CPU and GPU-based code variations and selects the fastest combination based on input parameters and device performance, significantly enhancing computational speed. The Liquid Engine employs a machine learning-based Agent to predict the optimal combination of implementations, adaptively responding to delays and performance variations.\n",
    "\n",
    "## In this tutorial:\n",
    "\n",
    "1. We will showcase basic examples of NanoPyx methods\n",
    "2. We will use the Liquid Engine in the NanoPyx library\n",
    "3. We will implement our own custom method in the Liquid Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using NanoPyx methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Install NanoPyx and it's dependencies\n",
    "\n",
    "NanoPyx is available through [PyPi](https://pypi.org/) so it can simply be pip installed:\n",
    "```shell\n",
    "!pip install nanopyx\n",
    "```\n",
    "\n",
    "To be used in a local jupyter notebook it is recommended that the optional dependencies for jupyter are installed:\n",
    "```shell\n",
    "!pip install nanopyx[jupyter]\n",
    "```\n",
    "\n",
    "If using Google Colab install the colab dependencies:\n",
    "```shell\n",
    "!pip install nanopyx[colab]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "!pip install nanopyx[colab] -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Let's use NanoPyx to load an example image\n",
    "\n",
    "NanoPyx contains several example image stacks that can be used to try it's different methods.\n",
    "You can access them through the following class:\n",
    "```python\n",
    "from nanopyx.data.download import ExampleDataManager\n",
    "```\n",
    "\n",
    "a) Let's import the class and list all available datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from nanopyx.data.download import ExampleDataManager\n",
    "\n",
    "edm = ExampleDataManager()\n",
    "edm.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Now let's load the SMLMS2013_HDTubulinAlexa647 using the [class method](https://henriqueslab.github.io/NanoPyx/nanopyx/data/download.html#ExampleDataManager):\n",
    "```python\n",
    "get_ZipTiffIterator(dataset_name, as_ndarray=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "image = edm.get_ZipTiffIterator(\"SMLMS2013_HDTubulinAlexa647\", as_ndarray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) let's look at the image by using stackview\n",
    "\n",
    "```python\n",
    "import stackview\n",
    "stackview.slice(image)\n",
    "```\n",
    "  \n",
    "NOTE: if using colab you will need to add this code before stackview to enable the widget:\n",
    "```python\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import stackview\n",
    "stackview.slice(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Using NanoPyx eSRRF to generate a super-resolved image\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from nanopyx import eSRRF\n",
    "sr_image = eSRRF(image, magnification=2)[0] # this function returns a tuple with index 0 corresponding to the image\n",
    "mean_projection = np.mean(sr_image, axis=0)\n",
    "```\n",
    "\n",
    "don't forget to display it with stackview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import numpy as np\n",
    "from nanopyx import eSRRF\n",
    "sr_image = eSRRF(image, magnification=2)[0]\n",
    "stackview.slice(np.mean(sr_image, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Let's compare the resolution of the original image and the super-resolved image using image decorrelation analysis\n",
    "\n",
    "```python\n",
    "from nanopyx import calculate_decorr_analysis\n",
    "resolution = calculate_decorr_analysis(image, pixel_size=1, pixel_units=\"nm\")\n",
    "```\n",
    "\n",
    "use 100 for the pixel size of the original image and 100/magnification for the eSRRF image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from nanopyx import calculate_decorr_analysis\n",
    "df_resolution = calculate_decorr_analysis(np.mean(image, axis=0), pixel_size=100)\n",
    "sr_resolution = calculate_decorr_analysis(np.mean(sr_image, axis=0), pixel_size=50)\n",
    "\n",
    "print(f\"DF resolution: {df_resolution:.2f} px and SR resolution: {sr_resolution:.2f} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using NanoPyx Liquid Engine to optimize image analysis\n",
    "\n",
    "NanoPyx uses the Liquid Engine at it's core. This allow us to have multiple implementations of the same algorithm (eSRRF for example) and the Liquid Engine's agent will decide on the best one to use for your input and hardware.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Let's import the 2D convolution method of NanoPyx and run it using a random image\n",
    "\n",
    "```python   \n",
    "import numpy as np\n",
    "from nanopyx.core.transform._le_convolution import Convolution\n",
    "\n",
    "img = np.random.random((25, 25)).astype(np.float32)\n",
    "kernel = np.ones((3, 3), dtype=np.float32)\n",
    "conv = Convolution()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import numpy as np\n",
    "from nanopyx.core.transform._le_convolution import Convolution\n",
    "\n",
    "img = np.random.random((25, 25)).astype(np.float32)\n",
    "kernel = np.ones((3, 3), dtype=np.float32)\n",
    "conv = Convolution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Benchmarking the different implementations\n",
    "  \n",
    "When there are no benchmarks available, the Liquid Engine will use any provided default benchmarks until it has 3 run times on your hardware. If no defaults are provided then it will randomly choosen between all available options.  \n",
    "  \n",
    "As part of the Liquid Engine, we have also created a benchmarking function that allows you to benchmark all implementations in your hardware for specific inputs.\n",
    "\n",
    "```python\n",
    "for i in range(3):\n",
    "    conv.benchmark(img, kernel)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "for i in range(3):\n",
    "    conv.benchmark(img, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Benchmark the same method but now using a bigger image and kernel\n",
    "\n",
    "```python   \n",
    "import numpy as np\n",
    "\n",
    "big_img = np.random.random((500, 500)).astype(np.float32)\n",
    "big_kernel = np.ones((5, 5), dtype=np.float32)\n",
    "\n",
    "for i in range(3):\n",
    "    conv.benchmark(big_img, big_kernel)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import numpy as np\n",
    "\n",
    "big_img = np.random.random((500, 500)).astype(np.float32)\n",
    "big_kernel = np.ones((5, 5), dtype=np.float32)\n",
    "\n",
    "for i in range(3):\n",
    "    conv.benchmark(big_img, big_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Now when calling .run() you will see that the agent will pick the fastest option for each case\n",
    "\n",
    "```python\n",
    "out = conv.run(img, kernel)\n",
    "out2 = conv.run(big_img, big_kernel)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "out = conv.run(img, kernel)\n",
    "out2 = conv.run(big_img, big_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 What if you already have benchmarks but not of the specific input parameters that you will be testing?\n",
    "\n",
    "On those scenarios the Liquid Engine agent employs fuzzy logic to find the closest known example.  \n",
    "Try running the conv for an image with shape=(150, 150) and for another with shape=(550, 550), they should use the fastest run_type according to the previous images of (100, 100) and (500, 500), respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "out = conv.run(np.random.random((150, 150)).astype(np.float32), np.ones((3, 3), dtype=np.float32))\n",
    "out2 = conv.run(np.random.random((550, 550)).astype(np.float32), np.ones((5, 5), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Forcing a specific run_type to run\n",
    "\n",
    "You also have the option of manually forcing the Liquid Engine to use a specific implementation using the `run_type=\"run_type_name\"`optional argument.\n",
    "\n",
    "```python\n",
    "out = conv.run(img, kernel, run_type=\"threaded\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "out = conv.run(img, kernel, run_type=\"threaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6.1 You can inspect the class to find which run_types are available\n",
    "\n",
    "```python\n",
    "print(conv._run_types.keys())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "print(conv._run_types.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing your own method using the Liquid Engine\n",
    "\n",
    "The Liquid Engine is a standalone package that is pip installable:\n",
    "```shell\n",
    "pip install liquid_engine\n",
    "```\n",
    "\n",
    "It's a requirement of NanoPyx so you should already have it in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Let's create our own method using the Liquid Engine but we need to do that inside a .py file and not a jupyter notebook\n",
    "\n",
    "This is mainly due to how we dynamically check class and methods name so that we can use it for the automatic benchmarking.  \n",
    "\n",
    "a) Start by creating myliquidengine.py file in the same folder as this notebook or in the collab runtime workspace  \n",
    "  \n",
    "b) Add the following code to it:  \n",
    "```python\n",
    "import numpy as np\n",
    "from liquid_engine import LiquidEngine\n",
    "\n",
    "from skimage.restoration import denoise_nl_means\n",
    "\n",
    "class MyLiquidEngineClass(LiquidEngine):\n",
    "    def __init__(self):\n",
    "        self._designation = \"MyLiquidEngineClass\"\n",
    "        super().__init__()\n",
    "\n",
    "    def run(self, image: np.ndarray, patch_size: int, patch_distance: int, h:float, sigma:float, run_type=None):\n",
    "        return self._run(image, patch_size=patch_size, patch_distance=patch_distance, h=h, sigma=sigma)\n",
    "\n",
    "    def _run_ski_nlm_1(self, image, patch_size, patch_distance, h, sigma):\n",
    "        return denoise_nl_means(image, patch_size=patch_size, patch_distance=patch_distance, h=h, sigma=sigma, fast_mode=True)\n",
    "\n",
    "    def _run_ski_nlm_2(self, image, patch_size, patch_distance, h, sigma):\n",
    "        return denoise_nl_means(image, patch_size=patch_size, patch_distance=patch_distance, h=h, sigma=sigma, fast_mode=False)\n",
    "```\n",
    "\n",
    "Code explanation:\n",
    "- run(args): is the call to run the method, any arguments need to be passed here and it should always call _run()\n",
    "- _run(args): private method defined as part of the Liquid Engine that looks for _run_runtype_name methods and treats them as different implementations to be selected by the agent.\n",
    "- _run_runtype_name_1, _run_runtype_name_2, ...: different implementations to be selected by the agent, determined by starting it's naming with _run and should always be followed by _runtype_name (whatever you want to call your implementation)  \n",
    "\n",
    "---\n",
    "\n",
    "In this example we will be using the non-local means denoising from scikit-image which comes with two different implementations controlled by the `fast_mode` argument.  \n",
    "\n",
    "  \n",
    "\n",
    "c) Let's import the class defined in myliquidengine.py file and initialize it:  \n",
    "```python\n",
    "from myliquidengine import MyLiquidEngineClass\n",
    "\n",
    "myle = MyLiquidEngineClass()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from myliquidengine import MyLiquidEngineClass\n",
    "\n",
    "myle = MyLiquidEngineClass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Now let's benchmark it using a random image with shape=(100, 100)\n",
    "\n",
    "For the remaining parameters, use `patch_size=5`, `patch_distance=10`, `h=0.1`and `sigma=1`   \n",
    "\n",
    "\n",
    "```python\n",
    "img = np.random.random((100, 100)).astype(np.float32)\n",
    "for i in range(3):\n",
    "    myle.benchmark(img, 5, 10, 0.1, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "img = np.random.random((100, 100)).astype(np.float32)\n",
    "for i in range(3):\n",
    "    myle.benchmark(img, 5, 10, 0.1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Let's call the run method with the same parameters and check it's selecting the appropriate run_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "out = myle.run(img, 5, 10, 0.1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocb_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
